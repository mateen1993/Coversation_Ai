{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jdpr13Gi5aTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7fd9f2-467a-495b-a859-6603dfdf9423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install NLTK\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import the word_tokenize function from nltk.tokenize\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG5IZau-5uYK",
        "outputId": "c120bb7e-73b1-4de7-be63-21103a26e268"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a variable ‘text’ that contains a paragraph of at least 4 sentences\n",
        "text = \"\"\"Natural Language Processing, or NLP, is a field of artificial intelligence that focuses on the interaction between computers and humans using language.\n",
        "It enables machines to understand, interpret, and generate human language.\n",
        "NLP is used in various applications, from language translation and sentiment analysis to chatbots and voice recognition.\n",
        "With advancements in NLP, computers can better assist us in our daily tasks, making technology more accessible.\"\"\""
      ],
      "metadata": {
        "id": "76yyfoEw1lCX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Use the word_tokenize function to tokenize the text into words\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Step 5: Print the list of tokens\n",
        "print(\"List of Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyaKRlz41kjh",
        "outputId": "245f03cf-b733-4492-e24a-135d27947aaf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Tokens: ['Natural', 'Language', 'Processing', ',', 'or', 'NLP', ',', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'using', 'language', '.', 'It', 'enables', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'NLP', 'is', 'used', 'in', 'various', 'applications', ',', 'from', 'language', 'translation', 'and', 'sentiment', 'analysis', 'to', 'chatbots', 'and', 'voice', 'recognition', '.', 'With', 'advancements', 'in', 'NLP', ',', 'computers', 'can', 'better', 'assist', 'us', 'in', 'our', 'daily', 'tasks', ',', 'making', 'technology', 'more', 'accessible', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Count the number of tokens in the text\n",
        "token_count = len(tokens)\n",
        "print(\"Number of Tokens:\", token_count)"
      ],
      "metadata": {
        "id": "OVxqC5Rc5_6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ec70b9-3737-4b91-d92d-f845eed0614e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tokens: 77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Identify the frequency of each token using nltk.FreqDist\n",
        "frequency_dist = FreqDist(tokens)\n",
        "print(\"Token Frequencies:\")\n",
        "for word, freq in frequency_dist.items():\n",
        "    print(f\"{word}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CgiHR4z3pbu",
        "outputId": "3c92f9ae-1dd6-49f2-ca20-81841bc031b4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Frequencies:\n",
            "Natural: 1\n",
            "Language: 1\n",
            "Processing: 1\n",
            ",: 7\n",
            "or: 1\n",
            "NLP: 3\n",
            "is: 2\n",
            "a: 1\n",
            "field: 1\n",
            "of: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "that: 1\n",
            "focuses: 1\n",
            "on: 1\n",
            "the: 1\n",
            "interaction: 1\n",
            "between: 1\n",
            "computers: 2\n",
            "and: 4\n",
            "humans: 1\n",
            "using: 1\n",
            "language: 3\n",
            ".: 4\n",
            "It: 1\n",
            "enables: 1\n",
            "machines: 1\n",
            "to: 2\n",
            "understand: 1\n",
            "interpret: 1\n",
            "generate: 1\n",
            "human: 1\n",
            "used: 1\n",
            "in: 3\n",
            "various: 1\n",
            "applications: 1\n",
            "from: 1\n",
            "translation: 1\n",
            "sentiment: 1\n",
            "analysis: 1\n",
            "chatbots: 1\n",
            "voice: 1\n",
            "recognition: 1\n",
            "With: 1\n",
            "advancements: 1\n",
            "can: 1\n",
            "better: 1\n",
            "assist: 1\n",
            "us: 1\n",
            "our: 1\n",
            "daily: 1\n",
            "tasks: 1\n",
            "making: 1\n",
            "technology: 1\n",
            "more: 1\n",
            "accessible: 1\n"
          ]
        }
      ]
    }
  ]
}